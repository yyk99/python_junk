{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with SQL\n",
    "# Found here:\n",
    "# https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "    \"https://raw.github.com/pandas-dev\"\n",
    "    \"/pandas/master/pandas/tests/io/data/csv/tips.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-sister",
   "metadata": {},
   "source": [
    "## SELECT\n",
    "In SQL, selection is done using a comma-separated list of columns you’d like to select (or a * to select all columns):\n",
    "<br>\n",
    "~~~\n",
    "SELECT total_bill, tip, smoker, time\n",
    "FROM tips;\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips[[\"total_bill\", \"tip\", \"smoker\", \"time\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-allen",
   "metadata": {},
   "source": [
    "In SQL, you can add a calculated column:\n",
    "```\n",
    "SELECT *, tip/total_bill as tip_rate\n",
    "FROM tips;\n",
    "```\n",
    "With pandas, you can use the DataFrame.assign() method of a DataFrame to append a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.assign(tip_rate=tips[\"tip\"] / tips[\"total_bill\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-consensus",
   "metadata": {},
   "source": [
    "## WHERE\n",
    "Filtering in SQL is done via a WHERE clause.\n",
    "```\n",
    "SELECT *\n",
    "FROM tips\n",
    "WHERE time = 'Dinner';\n",
    "```\n",
    "DataFrames can be filtered in multiple ways; the most intuitive of which is using boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips[tips[\"total_bill\"] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dinner = tips[\"time\"] == \"Dinner\"\n",
    "is_dinner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dinner.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips[is_dinner]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-saturday",
   "metadata": {},
   "source": [
    "Just like SQL’s OR and AND, multiple conditions can be passed to a DataFrame using | (OR) and & (AND).\n",
    "\n",
    "Tips of more than $5 at Dinner meals:\n",
    "```\n",
    "SELECT *\n",
    "FROM tips\n",
    "WHERE time = 'Dinner' AND tip > 5.00;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips[(tips[\"time\"] == \"Dinner\") & (tips[\"tip\"] > 5.00)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-identification",
   "metadata": {},
   "source": [
    "Tips by parties of at least 5 diners OR bill total was more than $45:\n",
    "```\n",
    "SELECT *\n",
    "FROM tips\n",
    "WHERE size >= 5 OR total_bill > 45;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips[(tips[\"size\"] >= 5) | (tips[\"total_bill\"] > 45)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-upgrade",
   "metadata": {},
   "source": [
    "NULL checking is done using the notna() and isna() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(\n",
    "    {\"col1\": [\"A\", \"B\", np.NaN, \"C\", \"D\"], \"col2\": [\"F\", np.NaN, \"G\", \"H\", \"I\"]}\n",
    ")\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-blast",
   "metadata": {},
   "source": [
    "Assume we have a table of the same structure as our DataFrame above. We can see only the records where col2 IS NULL with the following query:\n",
    "```\n",
    "SELECT *\n",
    "FROM frame\n",
    "WHERE col2 IS NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame[\"col2\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-dream",
   "metadata": {},
   "source": [
    "Getting items where col1 IS NOT NULL can be done with notna().\n",
    "```\n",
    "SELECT *\n",
    "FROM frame\n",
    "WHERE col1 IS NOT NULL;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[frame[\"col1\"].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-romania",
   "metadata": {},
   "source": [
    "## GROUP BY\n",
    "In pandas, SQL’s GROUP BY operations are performed using the similarly named groupby() method. groupby() typically refers to a process where we’d like to split a dataset into groups, apply some function (typically aggregation) , and then combine the groups together.\n",
    "\n",
    "A common SQL operation would be getting the count of records in each group throughout a dataset. For instance, a query getting us the number of tips left by sex:\n",
    "```\n",
    "SELECT sex, count(*)\n",
    "FROM tips\n",
    "GROUP BY sex;\n",
    "/*\n",
    "Female     87\n",
    "Male      157\n",
    "*/\n",
    "```\n",
    "The pandas equivalent would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby(\"sex\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-wings",
   "metadata": {},
   "source": [
    "Notice that in the pandas code we used size() and not count(). This is because count() applies the function to each column, returning the number of NOT NULL records within each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby(\"sex\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-residence",
   "metadata": {},
   "source": [
    "Alternatively, we could have applied the count() method to an individual column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby(\"sex\")[\"total_bill\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-employment",
   "metadata": {},
   "source": [
    "Multiple functions can also be applied at once. For instance, say we’d like to see how tip amount differs by day of the week - <font color='red'>agg()</font> allows you to pass a dictionary to your grouped DataFrame, indicating which functions to apply to specific columns.\n",
    "```\n",
    "SELECT day, AVG(tip), COUNT(*)\n",
    "FROM tips\n",
    "GROUP BY day;\n",
    "/*\n",
    "Fri   2.734737   19\n",
    "Sat   2.993103   87\n",
    "Sun   3.255132   76\n",
    "Thu  2.771452   62\n",
    "*/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby(\"day\").agg({\"tip\": np.mean, \"day\": np.size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-honor",
   "metadata": {},
   "source": [
    "Grouping by more than one column is done by passing a list of columns to the groupby() method.\n",
    "```\n",
    "SELECT smoker, day, COUNT(*), AVG(tip)\n",
    "FROM tips\n",
    "GROUP BY smoker, day;\n",
    "/*\n",
    "smoker day\n",
    "No     Fri      4  2.812500\n",
    "       Sat     45  3.102889\n",
    "       Sun     57  3.167895\n",
    "       Thu    45  2.673778\n",
    "Yes    Fri     15  2.714000\n",
    "       Sat     42  2.875476\n",
    "       Sun     19  3.516842\n",
    "       Thu    17  3.030000\n",
    "*/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.groupby([\"smoker\", \"day\"]).agg({\"tip\": [np.size, np.mean]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-squad",
   "metadata": {},
   "source": [
    "## JOIN\n",
    "JOINs can be performed with join() or merge(). By default, join() will join the DataFrames on their indices. Each method has parameters allowing you to specify the type of join to perform (LEFT, RIGHT, INNER, FULL) or the columns to join on (column names or indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"key\": [\"A\", \"B\", \"C\", \"D\"], \"value\": np.random.randn(4)})\n",
    "\n",
    "df2 = pd.DataFrame({\"key\": [\"B\", \"D\", \"D\", \"E\"], \"value\": np.random.randn(4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-fountain",
   "metadata": {},
   "source": [
    "Assume we have two database tables of the same name and structure as our DataFrames.\n",
    "\n",
    "Now let’s go over the various types of JOINs.\n",
    "\n",
    "## INNER JOIN\n",
    "```\n",
    "SELECT *\n",
    "FROM df1\n",
    "INNER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge performs an INNER JOIN by default\n",
    "pd.merge(df1, df2, on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-tucson",
   "metadata": {},
   "source": [
    "merge() also offers parameters for cases when you’d like to join one DataFrame’s column with another DataFrame’s index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df2 = df2.set_index(\"key\")\n",
    "\n",
    "pd.merge(df1, indexed_df2, left_on=\"key\", right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-studio",
   "metadata": {},
   "source": [
    "## LEFT OUTER JOIN\n",
    "Show all records from <font color=\"red\">df1</font>.\n",
    "```\n",
    "SELECT *\n",
    "FROM df1\n",
    "LEFT OUTER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-respect",
   "metadata": {},
   "source": [
    "## RIGHT JOIN\n",
    "Show all records from df2.\n",
    "```\n",
    "SELECT *\n",
    "FROM df1\n",
    "RIGHT OUTER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\", how=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-interference",
   "metadata": {},
   "source": [
    "## FULL JOIN\n",
    "pandas also allows for FULL JOINs, which display both sides of the dataset, whether or not the joined columns find a match. As of writing, FULL JOINs are not supported in all RDBMS (MySQL).\n",
    "\n",
    "Show all records from both tables.\n",
    "```\n",
    "SELECT *\n",
    "FROM df1\n",
    "FULL OUTER JOIN df2\n",
    "  ON df1.key = df2.key;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on=\"key\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-definition",
   "metadata": {},
   "source": [
    "## Question: SQL query to find record with ID not in another table\n",
    "\n",
    "Use LEFT JOIN\n",
    "```\n",
    "SELECT  a.*\n",
    "FROM    table1 a\n",
    "            LEFT JOIN table2 b\n",
    "                on a.ID = b.ID\n",
    "WHERE   b.id IS NULL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\"key\": [\"A\", \"B\", \"C\", \"D\"], \"value\": np.random.randn(4)})\n",
    "\n",
    "b = pd.DataFrame({\"key\": [\"B\", \"D\", \"D\", \"E\"], \"value\": np.random.randn(4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = pd.merge(a, b, on=\"key\", how=\"left\")\n",
    "ab[ab['value_y'].isna()][['key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame({\"key\": [\"A\", \"B\", \"C\", \"D\"]})\n",
    "\n",
    "B = pd.DataFrame({\"key\": [\"B\", \"D\", \"D\", \"E\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = pd.merge(A, B, on=\"key\", how=\"left\")\n",
    "# ab[ab['value_y'].isna()][['key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 2, 4, 1])\n",
    "b = np.array([3, 4, 5, 6])\n",
    "np.setdiff1d(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = A.key.unique()\n",
    "b = B.key.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.setdiff1d(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-subscription",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
